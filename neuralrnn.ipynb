{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neuralrnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQaz2AyMvKjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Clone the custom reposistory from Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "print ('mounted drive')\n",
        "\n",
        "#copy from Drive to /content\n",
        "!cp /content/gdrive/My\\ Drive/chatbot-rnn.zip /content\n",
        "\n",
        "#unzip the zip\n",
        "!unzip /content/chatbot-rnn.zip\n",
        "\n",
        "#remove the nolonger needed .zip\n",
        "!rm /content/chatbot-rnn.zip\n",
        "\n",
        "# move the chatbot-rnn back to root content\n",
        "!mv /content/content/chatbot-rnn /content\n",
        "!rm -rf /content/content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGL0UbntLLjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title install required packages\n",
        "\n",
        "\n",
        "#install all packages needed to run \n",
        "!pip install unidecode discord arg argparse utils pillow tensorflow-gpu keras scipy keras tensorflow numpy h5py pyyaml absl-py termcolor gast tensorboard mock setuptools django corpus chatbot --upgrade\n",
        "\n",
        "#import all the required packages(might not be necessary but did it anyway)\n",
        "import numpy\n",
        "import utils\n",
        "import argparse\n",
        "import keras\n",
        "import tensorflow\n",
        "from unidecode import unidecode\n",
        "import unidecode \n",
        "\n",
        "\n",
        "#check to see what device youre running on\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "print ('**your notebook is currently running on Tesla T4**')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dXtYUAahaBv",
        "colab_type": "text"
      },
      "source": [
        "---------------------------------------------------------------------------------------------------------------------------------\n",
        "                                            \n",
        "                                                         OPTIONAL\n",
        "---------------------------------------------------------------------------------------------------------------------------------\n",
        "                                                         \n",
        "                                                            []\n",
        "                                                            []\n",
        "                                                            []\n",
        "                                                            []\n",
        "                                                            []\n",
        "                                                            []\n",
        "                                                            []\n",
        "                                                            []\n",
        "                                                                             \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNG4034EiPkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Download the pretrained model directly from google drive\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1rRRY-y1KdVk4UB5qhu7BjQHtfadIOmMk' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1rRRY-y1KdVk4UB5qhu7BjQHtfadIOmMk\" -O reddit.zip && rm -rf /tmp/cookies.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-loon1ECQia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Prep pretrained model\n",
        "!unzip /content/reddit.zip \n",
        "!mv /content/reddit /content/chatbot-rnn/models\n",
        "\n",
        "#Clean Up the excess\n",
        "!rm -r reddit.zip \n",
        "!rm -r __MACOSX"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ftK7QDhhf9n",
        "colab_type": "text"
      },
      "source": [
        "---------------------------------------------------------------------------------------------------------------------------------\n",
        "                                            \n",
        "                                                      \n",
        "---------------------------------------------------------------------------------------------------------------------------------\n",
        "                                                         \n",
        "                                                            []\n",
        "                                                            []\n",
        "                                                            []\n",
        "                                                            []\n",
        "                                                            []\n",
        "                                                            []\n",
        "                                                            []\n",
        "                                                            []\n",
        "                                                                             \n",
        "---------------------------------------------------------------------------------------------------------------------------------\n",
        "                                                         \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "proZCKg6MUvf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title download the data for trainning\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1s77S7COjrb3lOnfqvXYfn7sW_x5U1_l9' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1s77S7COjrb3lOnfqvXYfn7sW_x5U1_l9\" -O data.zip && rm -rf /tmp/cookies.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yodVXLcxMiVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title prep training data\n",
        "print ('uncompressing data.zip')\n",
        "!unzip /content/data.zip\n",
        "print ('succesfully uncompressed data.zip')\n",
        "print ('moving reddit to chatbot-rnn')\n",
        "!mv /content/reddit /content/chatbot-rnn/data\n",
        "print ('moved to data')\n",
        "!rm /content/data.zip\n",
        "print ('deleted data.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0cw1pHsWcT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#simple code to run the chatbot\n",
        "%cd /content/chatbot-rnn\n",
        "!python chatbot.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxhFL0BZYaNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#simple code to run the ((discord chatbot))\n",
        "%cd /content/chatbot-rnn\n",
        "!python discord_bot.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qL7svihWGW_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Test model\n",
        "Run_type = \"chatbot-discord\" #@param [\"chatbot\", \"chatbot-discord\"]\n",
        "#run the chatbot\n",
        "\n",
        "if Mode == \"Chatbot\":\n",
        "  !python chatbot.py\n",
        "if Mode == \"Chatbot-discord\":\n",
        "  !python discord_chatbot.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYk_h2gR1CcX",
        "colab_type": "code",
        "outputId": "c73e77c8-4e40-43fd-ce3b-14d5c9b2394f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#@title zip up and save to drive\n",
        "#zip the folder chatbot-rnn\n",
        "\n",
        "#Zip format = !zip -r -q \"filename\" \"directory\"\n",
        "print ('--zipping up the content')\n",
        "!zip -r -q chatbot-rnn.zip /content/chatbot-rnn\n",
        "print ('--.zip created!')\n",
        "\n",
        "#copy from content/chatbot-rnn to Gdrive\n",
        "print ('--copying chatbot-rnn to Gdrive')\n",
        "!cp /content/chatbot-rnn.zip /content/gdrive/My\\ Drive/\n",
        "print ('--succesfully back it up to Gdrive')\n",
        "#clean up the zip incase its get in the way\n",
        "!rm /content/chatbot-rnn.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--zipping up the content\n",
            "--.zip created!\n",
            "--copying chatbot-rnn to Gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y87MZL2uiGzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/chatbot-rnn\n",
        "!python "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfOfq5T0UQa-",
        "colab_type": "text"
      },
      "source": [
        "---------------------------------------------------------------------------------------------------------------------------------\n",
        "                                            \n",
        "                                            WIP scripts dont run these just yet\n",
        "---------------------------------------------------------------------------------------------------------------------------------\n",
        "                                                         \n",
        "                                                            []\n",
        "                                                            []\n",
        "                                                            []\n",
        "                                                            []\n",
        "                                                            []\n",
        "                                                            []\n",
        "                                                            []\n",
        "                                                            []\n",
        " ---------------------------------------------------------------------------------------------------------------------------------  ---------------------------------------------------------------------------------------------------------------------------------     ---------------------------------------------------------------------------------------------------------------------------------                                                                    \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKZTTgOUXCiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv /content/discord_bot.py /content/chatbot-rnn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKPDYub9RWr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Training script WIP (dont run this just yet)\n",
        "%cd /content/chatbot-rnn\n",
        "!python train.py "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7pN9UEKM6XO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dont run this ... like at all, this is mostly for testing\n",
        "#copy stuff\n",
        "!cp /content/chatbot-rnn/models/reddit/chars_vocab.pkl /content/chatbot-rnn/models\n",
        "!cp /content/chatbot-rnn/models/reddit/checkpoint /content/chatbot-rnn/models\n",
        "!cp /content/chatbot-rnn/models/reddit/config.pkl /content/chatbot-rnn/models\n",
        "!cp /content/chatbot-rnn/models/reddit/model.ckpt-4735000.data-00000-of-00001 /content/chatbot-rnn/models\n",
        "!cp /content/chatbot-rnn/models/reddit/model.ckpt-4735000.index /content/chatbot-rnn/models\n",
        "!cp /content/chatbot-rnn/models/reddit/model.ckpt-4735000.meta /content/chatbot-rnn/models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75M_KV5gfWgv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print ('zipping up the model')\n",
        "!zip -r -q reddit.zip . /reddit\n",
        "print ('done zipping up the files')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}